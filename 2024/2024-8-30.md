# 2024 年 8 月 30 日

重新梳理了一遍 `Co-SLAM` 的论文，整篇论文唯一值得借鉴的点是**全局 BA**，这是提升精度的核心，但是关键帧太多又达不到实时，所以每个关键帧只存 5% 的像素。至于其他的**空洞补全**、**OneBlob** 等就是讲故事了。

阅读了 `Co-SLAM` 的源码，`tracking`、`mapping`、`scene representation` 三大模块，网络部分用的还是 `pytorch` 自带的 `tinycudann`。