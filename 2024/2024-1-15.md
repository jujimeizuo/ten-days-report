# 2024 年 1 月 15 日

## 基于 InternLM 和 LangChain 搭建知识库

- 搭建流程：
    1. 环境配置
    2. 知识库搭建
        1. 数据收集
        2. 加载数据
        3. 构建向量数据库
    3. 接入 LangChain
    4. 构建检索问答链
        1. 加载向量数据库
        2. 实例化自定义 LLM 与 Prompt Template
        3. 构建检索问答链
    5. 部署 Web Demo
- 复现
    <center><img src="https://cdn.jujimeizuo.cn/note/llm/internlm/hw_3_1.jpg" width="50%"></center>

##  XTuner 大模型单卡低成本微调

笔记链接：https://note.jujimeizuo.cn/llm/internlm/lec4/

- 用 `internlm-chat-7b` 作为基座模型，自定义数据集，用 `XTuner` 工具进行微调。
- 用 MS-Agent 数据集赋予 LLM 以 Agent 能力，简单来说可以通过学习对话列表，让 LLM 能够如何调用插件以及生成请求。
- `InternLM-Chat` 个人小助手认知微调，如下所示：
    - 微调前
    <center> <img src="https://cdn.jujimeizuo.cn/note/llm/internlm/hw_4_1.jpg" width="50%"></center>
    
    - 微调后
    <center> <img src="https://cdn.jujimeizuo.cn/note/llm/internlm/hw_4_2.jpg" width="50%"></center>
- 将模型权重上传到
    - Hugging Face: https://huggingface.co/jujimeizuo/assistant-jujimeizuo/tree/main
    - OpenXLab: https://openxlab.org.cn/models/detail/jujimeizuo/jujimeizuo_assistant_model

## 下一步学习计划

- MoE 混合专家模型
- RLHF 强化学习
- LMDeploy 大模型量化部署
- OpenCompass 大模型评测